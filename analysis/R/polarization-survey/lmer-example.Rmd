---
title: Regression Analysis with lmerTest Tutorial
output: html_document
---

```{r include = FALSE}
library(lmerTest)
library(report)
library(lme4)
```

## Simulating Survey Analysis

```{r}
data <- data.frame(
  participant_id = rep(1:100, each = 4),  # 100 participants, 4 text pairs each
  treatment = rep(c("LLM", "Human", "Placebo"), each = 4, times = 100),
  tweet_bias = rep(c("left", "right"), times = 200),  # Alternating left/right biases
  political_leaning = sample(c("liberal", "moderate", "conservative"), 400, replace = TRUE),
  original_polarization = rnorm(400, mean = 3, sd = 1),
  treated_polarization = rnorm(400, mean = 2.5, sd = 1),
  choice = sample(c("original", "treated"), 400, replace = TRUE)
)
sample(data)
```

### **RQ1** Can LLMs mitigate textual polarization in social media texts?

Logistic Regression for mitigation effect

```{r rq1}
# binary outcome: 1 = treated is polarized, 0 = otherwise
data$treated_less_polarized <- ifelse(data$choice == "treated", 1, 0)

model_rq1 <- glmer(treated_less_polarized ~ treatment + tweet_bias + political_leaning + 
                   (1 | participant_id), 
                   data = data, family = "binomial")
summary(model_rq1)
```

```{r}
report(model_rq1)
```

## **RQ2** Can LLMs significantly reduce perceived polarization in social media texts?
## **RQ3** Can LLMs mitigate textual polarization as good as humans?

```{r}
# Polarization difference (original - treated)
data$polarization_diff <- data$original_polarization - data$treated_polarization

# Compare LLM vs. Placebo
data_llm_vs_placebo <- subset(data, treatment %in% c("LLM", "Placebo"))
model_rq2 <- lmer(polarization_diff ~ treatment + tweet_bias + political_leaning + 
                  (1 | participant_id), 
                  data = data_llm_vs_placebo)
summary(model_rq2)
```
```{r}
report(model_rq2)
```
```{r}
# Compare LLM vs. Human
data_llm_vs_human <- subset(data, treatment %in% c("LLM", "Human"))
model_rq3 <- lmer(polarization_diff ~ treatment + tweet_bias + political_leaning + 
                  (1 | participant_id), 
                  data = data_llm_vs_human)
summary(model_rq3)
```
```{r}
report(model_rq3)
```

## **RQ4** Does political bias influence the participants' perception of textual polarization?

```{r}
model_rq4 <- lmer(original_polarization ~ tweet_bias * political_leaning + 
                  (1 | participant_id), data = data)
summary(model_rq4)
```
```{r}
report(model_rq4)
```

